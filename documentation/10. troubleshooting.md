# troubleshooting.md

# Comprehensive Troubleshooting Guide

## 1. Factory Registration Issues

If you encounter errors related to factory registration, such as `'ResearchAgent' object is not callable` or `Factory for content_generation is not callable`, this indicates an issue with how agents or workflows are registered in the system's registry.

### 1.1 Common Factory Errors

```
ERROR: Error creating agent research of type research: 'ResearchAgent' object is not callable
ERROR: Registered factory for content_generation is not callable
```

### 1.2 Solution 1: Registry Cleanup Function

Add a registry cleanup function to your initialization code:

```python
# In your __init__.py or main initialization file
def _ensure_callable_factories():
    """Ensure all factories in the registry are callable functions."""
    from .agents.factory import agent_registry
    from .workflows.factory import workflow_registry
    from .core.logging import get_logger
    
    logger = get_logger("registry_fix")
    
    # Fix agent factories
    for name in list(agent_registry.list()):
        try:
            factory = agent_registry._factories.get(name)
            if factory and not callable(factory):
                logger.warning(f"Fixing non-callable agent factory: {name}")
                
                # Create a proper factory function based on the agent type
                if name == "research":
                    def research_factory(agent_id=None, **kwargs):
                        from .agents.research import ResearchAgent
                        return ResearchAgent(agent_id=agent_id or "research", **kwargs)
                    agent_registry._factories[name] = research_factory
                
                # ... Fix other agent types similarly
        
        except Exception as e:
            logger.error(f"Error fixing agent factory {name}: {str(e)}")
    
    # Fix workflow factories in a similar way
    # ...
```

### 1.3 Solution 2: Lambda Functions for Registration

When registering factories, use lambda functions to ensure they're callable:

```python
# Instead of directly registering the class or instance:
register_agent_factory("research", ResearchAgent)  # WRONG

# Use a lambda function:
register_agent_factory(
    "research", 
    lambda agent_id=None, **kwargs: ResearchAgent(agent_id=agent_id or "research", **kwargs)
)
```

### 1.4 Solution 3: Implement Fallback in Factory Methods

Add robust error handling and fallbacks in your creation methods:

```python
def create_agent(agent_type, agent_id=None, **kwargs):
    agent_id = agent_id or agent_type
    
    try:
        # First try direct instantiation as a fallback
        try:
            if agent_type == "research":
                from .research import ResearchAgent
                return ResearchAgent(agent_id=agent_id, **kwargs)
                
            # ... Handle other agent types
                
        except ImportError:
            pass
            
        # Then try the registry
        if agent_type in agent_registry.list():
            factory = agent_registry.get(agent_type)
            
            if callable(factory):
                try:
                    return factory(agent_id=agent_id, **kwargs)
                except TypeError:
                    pass
                    
        # Last resort: dynamic import
        # ...
            
    except Exception as e:
        logger.error(f"Error creating agent {agent_type}: {str(e)}")
        raise
```

## 2. Workflow Factory Registration Issues

The system can encounter factory registration issues where workflow factories are not callable. To prevent or fix these problems:

### 2.1 Workflow Registration Precedence Issue

A critical issue can occur when workflows are registered twice - once properly with lambda functions and once incorrectly with workflow instances. The incorrect registration can overwrite the proper one, leading to "not callable" errors:

```python
# CORRECT - Will work properly
register_workflow_factory(
    "research_only",
    lambda **kwargs: DeterministicWorkflow(agents=[create_agent("research")], **kwargs),
    {"description": "Research workflow"}
)

# INCORRECT - Will break the workflow if registered later
# This overwrites the previous registration!
register_workflow_factory(
    "research_only",
    DeterministicWorkflow(agents=[create_agent("research")]),  # Not a factory function!
    {"description": "Research workflow"}
)
```

To fix this issue:

1. Always use lambda functions when registering workflows
2. Add direct fallbacks in `create_workflow()` for critical workflows
3. Check for duplicate registrations in startup logs
4. When modifying workflow configurations, make sure to preserve the lambda pattern

### 2.2 Direct Workflow Creation Fallbacks

Add direct creation paths for commonly used workflows:

```python
def create_workflow(workflow_spec: str, **kwargs):
    """Create a workflow with direct fallbacks for reliability."""
    
    # Direct fallbacks for common workflows
    if workflow_spec == "research_only":
        logger.info("Creating research_only workflow directly")
        from .deterministic import DeterministicWorkflow
        from ..agents.factory import create_agent
        return DeterministicWorkflow(
            agents=[create_agent("research")],
            name="research_only"
        )
    elif workflow_spec == "content_generation":
        logger.info("Creating content_generation workflow directly")
        from .deterministic import DeterministicWorkflow
        from ..agents.factory import create_agent
        return DeterministicWorkflow(
            agents=[
                create_agent("research"),
                create_agent("strategy"),
                create_agent("writer"),
                create_agent("editor")
            ],
            name="content_generation"
        )
    
    # Continue with standard workflow creation logic...
```

### 2.3 Always Check Registry First

Ensure `create_workflow_by_type` always checks the registry before trying other methods:

```python
def create_workflow_by_type(workflow_type: str, **kwargs):
    """Create a workflow by type with proper registry checking."""
    
    # Always check registry first
    if workflow_type in workflow_registry.list():
        factory = workflow_registry.get(workflow_type)
        if callable(factory):
            try:
                return factory(**kwargs)
            except Exception as e:
                logger.warning(f"Factory call failed: {str(e)}")
                # Fall back to other methods
    
    # Standard types fallback
    if workflow_type == 'deterministic':
        from .deterministic import DeterministicWorkflow
        return DeterministicWorkflow(**kwargs)
    elif workflow_type == 'handoff':
        from .handoff import HandoffWorkflow
        return HandoffWorkflow(**kwargs)
    
    # Dynamic import as last resort
    try:
        module = importlib.import_module(f"aigen.workflows.{workflow_type.lower()}")
        class_name = "".join(word.capitalize() for word in workflow_type.split("_")) + "Workflow"
        workflow_class = getattr(module, class_name)
        return workflow_class(**kwargs)
    except (ImportError, AttributeError):
        raise ValueError(f"Unsupported workflow type: {workflow_type}")
```

### 2.4 Workflow Registration Architecture

The framework includes a two-level workflow registration architecture:

#### Base Workflow Types vs Concrete Workflow Instances

There are two kinds of registered workflows:

1. **Base Workflow Types** (like "deterministic" and "handoff"):
   - These are registered as workflow types in the factory system
   - They provide the execution strategy (sequential, handoff-based, etc.)
   - They're registered so they can be referenced by name in configuration files
   - Example: `create_workflow("deterministic")`

2. **Concrete Workflow Instances** (like "content_generation" and "research_only"):
   - These are pre-configured workflows with specific agent combinations
   - They're created using one of the base workflow types
   - They're registered for user convenience
   - Example: `create_workflow("content_generation")`

```python
# Registering a base workflow type
register_workflow_factory(
    "deterministic",  # Base type
    lambda agents=None, **kwargs: DeterministicWorkflow(agents=agents or [], **kwargs),
    {"description": "Sequential execution workflow"}
)

# Registering a concrete workflow instance
register_workflow_factory(
    "content_generation",  # Concrete instance
    lambda **kwargs: DeterministicWorkflow(
        agents=[
            create_agent("research"),
            create_agent("writer"),
            create_agent("editor")
        ],
        **kwargs
    ),
    {"description": "Complete content creation pipeline"}
)
```

### 2.5 UI Components and Workflow Registration

If you're building UI components that need to reference workflows, make sure they don't re-register workflows with instances:

```python
# INCORRECT - UI component registering workflow instances
def init_ui_workflows(self):
    # This causes issues by registering instances instead of factories
    register_workflow_factory(
        "research_only", 
        DeterministicWorkflow(agents=[create_agent("research")])  # ❌ Wrong!
    )

# CORRECT - UI component referencing workflows without re-registering
def get_workflow_config(self, name):
    # This just references workflow configurations without changing registration
    workflow_configs = {
        "research_only": {
            "agents": ["research"],
            "description": "Research-only workflow"
        }
    }
    return workflow_configs.get(name, {})
```

## 3. Agent Implementation Issues

### 3.1 Agent Not Found Issues

If your custom agent isn't being found by the system, check the following:

1. **Location**: Agents should be placed in either:
   - Main agents directory: `aigen/agents/*.py`
   - Custom agents directory: `aigen/agents/custom/*.py`

2. **Module Structure**: Ensure both directories have an `__init__.py` file to make them proper Python packages.

3. **Class Naming**: The agent class should follow either:
   - PascalCase: `TestAgent` (automatically detected)
   - camelCase: `testAgent` (automatically detected as fallback)

### 3.2 Import Errors

Custom agents must use absolute imports rather than relative ones:

```python
# CORRECT - Use absolute imports
from aigen.agents.base import AgentBase, AgentRole, AgentResponse
from aigen.core.context import Context
from aigen.core.errors import AgentError

# INCORRECT - Don't use relative imports 
from .base import AgentBase  # This will fail in custom subdirectories
```

### 3.3 Agent Factory System

The agent factory system uses multiple strategies to find and instantiate agents:

1. **Direct instantiation** for built-in agents
2. **Factory functions** for registered agents 
3. **Dynamic import** as a fallback, which:
   - First checks in main agents directory
   - Then checks in custom agents directory
   - Tries both PascalCase and camelCase class names

If you're having trouble with agent registration:
```python
from aigen.agents.factory import register_agent_factory

# Register with a factory function
register_agent_factory(
    "my_agent",  # Agent type ID
    lambda agent_id=None, **kwargs: MyAgent(agent_id=agent_id or "my_agent", **kwargs),
    {"description": "My custom agent"}  # Optional metadata
)
```

### 3.4 Common Warning: "Factory for [agent_name] is not callable"

If you see a warning like:
```
[12:08:33] ⚠️ WARNING: Factory for agent_22 is not callable, trying dynamic import
```

This indicates that:

1. The system found a registered factory for the agent, but it's not a callable function
2. This typically happens when an agent instance (object) was registered instead of a factory function
3. The system will fall back to dynamic import, which might still work but is less efficient

**No action is required** when you see this warning. The system will automatically:
1. Use dynamic import to find the appropriate agent module
2. Instantiate the agent class directly
3. Continue normal operation without interruption

### 3.5 Interface Compatibility Issues

All agents must:

1. **Inherit from AgentBase**:
   ```python
   class MyCustomAgent(AgentBase):
       # Implementation
   ```

2. **Implement the correct method signatures**:
   ```python
   async def execute(
       self, 
       context: Context,  # Must accept Context object first
       input_text: Optional[str] = None  # Input text is optional second param
   ) -> AgentResponse:  # Must return AgentResponse object
       # Implementation
   ```

3. **Handle context correctly**:
   ```python
   # Get input from context if not provided directly
   if input_text is None:
       input_text = context.get_latest_output() or "No input provided"
       
   # Store results in context
   context.store_output(self.agent_id, result)
   ```

4. **Return properly structured responses**:
   ```python
   return AgentResponse(
       content=result,
       agent_id=self.agent_id,
       success=True,
       metadata={"role": "custom"}
   )
   ```

## 4. SDK Integration Issues

### 4.1 OpenAI Agents SDK Configuration

#### ModelSettings Configuration Issues

The `model` parameter must be passed directly to the `Agent` constructor, not to the `ModelSettings` constructor:

```python
# CORRECT:
self.openai_agent = Agent(
    name="My Agent",
    instructions=instruction_fn,
    tools=self.tools,
    model=self.parameters.get("model", "gpt-4o"),  # ✅ model here
    model_settings=ModelSettings(
        temperature=0.7,                           # ✅ only temperature/other settings
        tool_choice="auto"                         # ✅ no model parameter here
    )
)

# INCORRECT - will cause runtime error:
self.openai_agent = Agent(
    name="My Agent",
    instructions=instruction_fn,
    tools=self.tools,
    model_settings=ModelSettings(
        model="gpt-4o",                           # ❌ Wrong! model should not be here
        temperature=0.7
    )
)
```

#### Trace ID Format Issues

When using the `trace()` function, ensure trace IDs always start with `trace_`:

```python
# CORRECT - use the SDK-provided function for guaranteed valid IDs:
from agents import gen_trace_id
trace_id = gen_trace_id()

# CORRECT - trace ID with proper prefix:
trace_id = f"trace_my_custom_id_{uuid.uuid4().hex[:8]}"

# INCORRECT - will cause API error:
trace_id = f"my_custom_id_{uuid.uuid4().hex[:8]}"
trace_id = f"workflow_{workflow_name}_{uuid.uuid4().hex[:8]}"
trace_id = str(uuid.uuid4())
```

### 4.2 Agent Implementation with OpenAI Agents SDK

When implementing agents that use the OpenAI Agents SDK, follow these best practices to avoid common errors:

#### Use Runner.run() Instead of agent.run()

```python
# INCORRECT - Will cause error: 'Agent' object has no attribute 'run'
response = await self.openai_agent.run(input_text)

# CORRECT - Always use Runner.run() to execute an agent
from agents import Runner
response = await Runner.run(self.openai_agent, input_text)
```

#### Access RunResult Properties Correctly

When processing the results returned by `Runner.run()`, use the correct property names:

```python
# INCORRECT - Will cause error: 'RunResult' object has no attribute 'content'
result = response.content

# CORRECT - Use final_output for the main text response
result = response.final_output
```

### 4.3 Runner Context Issues

When using the OpenAI Agents SDK Runner:
```python
# CORRECT: Don't pass the Context object directly to Runner
response = await Runner.run(
    self.openai_agent,
    input=input_text,
    context=None,  # Don't use our Context object here
    max_turns=self.parameters.get("max_turns", 10)
)
```

### 4.4 Example of Correctly Implemented Agent.execute() Method

```python
async def execute(self, context: Context, input_text: Optional[str] = None) -> AgentResponse:
    """Execute the agent with proper SDK patterns."""
    try:
        # Initialize if not already done
        if not hasattr(self, 'openai_agent') or self.openai_agent is None:
            await self.initialize()
        
        # Get input - either direct or from context
        if input_text is None:
            input_text = context.get_latest_output()
            
        if not input_text:
            return AgentResponse.error_response(
                self.agent_id, 
                "No input provided"
            )
        
        # CORRECT: Use Runner.run() from the SDK
        from agents import Runner
        response = await Runner.run(
            self.openai_agent,
            input=input_text,
            max_turns=self.parameters.get("max_turns", 10)
        )
        
        # CORRECT: Extract result using final_output
        if hasattr(response, 'final_output') and response.final_output:
            output = str(response.final_output)
        else:
            output = "No output generated"
        
        # Store in context
        context.store_output(self.agent_id, output)
        
        # CORRECT: Use set_metadata not add_metadata
        context.set_metadata(self.agent_id, {"word_count": len(output.split())})
        
        return AgentResponse(
            content=output,
            agent_id=self.agent_id,
            success=True
        )
        
    except Exception as e:
        logger.error(f"Error executing agent: {str(e)}")
        return AgentResponse.error_response(self.agent_id, str(e))
```

## 5. Response Object Issues

A common source of errors is confusing the different response objects returned at different levels of the system:

### 5.1 Response Object Hierarchy

1. **OpenAI Agents SDK Level**:
   - `Runner.run()` returns a `RunResult` object
   - Access text output via `.final_output`
   - Example: `result = response.final_output`

2. **Agent Level (Your Framework)**:
   - `agent.execute()` returns an `AgentResponse` object
   - Access text output via `.content`
   - Example: `output = response.content`

3. **Workflow Engine Level**:
   - `engine.execute_agent()` returns an `AgentResponse` 
   - `engine.execute()` returns a dictionary with result info
   - Example: `if result["status"] == "completed": return result["result"]`

### 5.2 Common Mistake: Mixing Response Types

```python
# INCORRECT - Mixing response types
# In a method that receives an AgentResponse but treats it like a RunResult:
def process_agent_output(response):
    text = response.final_output  # ❌ Wrong! AgentResponse has .content, not .final_output
    return text
```

```python
# CORRECT - Handle each response type appropriately
def process_agent_output(response):
    # Check the response type
    if hasattr(response, 'final_output'):  # It's a RunResult from OpenAI SDK
        return response.final_output
    elif hasattr(response, 'content'):     # It's an AgentResponse from our framework
        return response.content
    elif isinstance(response, dict) and "result" in response:  # It's from engine.execute()
        return response["result"]
    else:
        return str(response)  # Fallback
```

## 6. Single-Agent Workflow Issues

When creating single-agent workflows like "research_only", ensure the agent's output is properly formatted for direct display:

```python
# In research agent's execute method:
if not result.startswith("# Research Results"):
    # Add proper formatting for single-agent display
    formatted_result = f"""# Research Results on: {input_text}

{result}

---
*Research conducted by {self.agent_id} agent*
"""
    result = formatted_result
```

In DeterministicWorkflow, add special handling for single-agent workflows:

```python
# Single-agent workflow special handling
if len(self.agents) == 1:
    logger.info(f"Single-agent workflow completed with {agent_id}")
    if not context.get_output(agent_id):
        context.store_output(agent_id, response.content)
```

## 7. UI Component Issues

### 7.1 UI Component Type Mismatches with Gradio

When working with the Gradio-based UI, you may encounter errors related to component type mismatches. These typically occur when a function returns a data type incompatible with the UI component it's connected to.

#### Common Error: Dictionaries Passed to Markdown Components

A frequent error occurs when a dictionary is passed to a Gradio Markdown component, which expects a string:

```
Error: Cannot convert dict to str implicitly
```

This often happens after refactoring functions to return more structured data (dictionaries) while the UI components remain configured for string outputs.

#### Solution 1: Use Appropriate Component Types

Match your component types to your function return types:

```python
# INCORRECT - Will cause error if function returns a dictionary
result_display = gr.Markdown()

# CORRECT - Use JSON component for dictionary return types
result_display = gr.JSON()
```

#### Solution 2: Use Adapter Functions

Add adapter functions that convert between types:

```python
def dict_to_string_adapter(func):
    """Adapter to convert dictionary outputs to strings for Markdown components."""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        result = await func(*args, **kwargs)
        
        if isinstance(result, dict):
            # Format dictionary nicely for display
            if "status" in result and "message" in result:
                return result["message"]
            return str(result)
        return result
    return wrapper

# Then use it in your UI setup:
btn.click(
    dict_to_string_adapter(my_func),
    inputs=[...],
    outputs=[result_markdown]
)
```

#### Solution 3: Move Shared Adapter Functions to Utilities

For frequently used adapter functions, place them in a shared utilities module:

```python
# In aigen/ui/utils.py
import inspect
from functools import wraps
from typing import Any, Callable, Dict

def dict_to_string_adapter(func: Callable) -> Callable:
    """Adapter to convert dictionary outputs to strings for Markdown components."""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        if inspect.iscoroutinefunction(func):
            result = await func(*args, **kwargs)
        else:
            result = func(*args, **kwargs)
            
        if isinstance(result, dict):
            if "status" in result and "message" in result:
                return result["message"]
            return str(result)
        return result
    return wrapper

# Then import it where needed:
from aigen.ui.utils import dict_to_string_adapter
```

### 7.2 Best Practice: Consistency in Return Types

To prevent these issues:
- Design UI functions to have consistent return types
- Document expected return types for all UI-connected functions
- Use typing annotations to make return types explicit
- When refactoring, review all UI component connections
- Consider using more flexible components like HTML or JSON instead of Markdown
- Test UI changes thoroughly before deployment

## 8. Logging System Issues

### 8.1 Correct Logging Patterns

The logging system uses keyword arguments (`**kwargs`) for structured logging. A common mistake is passing dictionaries as positional arguments instead of using keyword arguments:

#### Incorrect vs Correct Logging Patterns

```python
# INCORRECT - Passing a dictionary as a positional argument
# Will cause: "Logger.info() takes 2 positional arguments but 3 were given"
logger.info(f"Searching for: '{query}'", {"results_count": results_count})  # ❌ Wrong!

# INCORRECT - Same issue with other logging methods
logger.success(f"Found {len(results)} results", {"time_taken": f"{elapsed_time:.2f}s"})  # ❌ Wrong!
```

```python
# CORRECT - Use keyword arguments instead of a dictionary
logger.info(f"Searching for: '{query}'", results_count=results_count)  # ✅ Correct

# CORRECT - Same pattern for all logging methods
logger.success(f"Found {len(results)} results", time_taken=f"{elapsed_time:.2f}s")
logger.warning(f"Process slow", threshold=threshold, actual_time=elapsed_time)
logger.error(f"Operation failed", error_code=code, error_message=str(e))
```

### 8.2 Complete Example with Proper Logging

```python
async def execute_search(query: str, max_results: int = 5) -> Dict[str, Any]:
    """Execute a search with proper logging."""
    start_time = time.time()
    
    try:
        # Log the search parameters correctly
        logger.info(f"Starting search for '{query}'", 
                   max_results=max_results, 
                   timestamp=datetime.now().isoformat())
        
        # Perform search operation...
        results = await search_api.execute(query, max_results)
        
        # Log success with keyword arguments
        elapsed_time = time.time() - start_time
        logger.success(f"Search completed successfully", 
                      results_count=len(results),
                      time_taken=f"{elapsed_time:.2f}s")
        
        return {
            "status": "success",
            "results": results,
            "meta": {"query": query, "time": elapsed_time}
        }
        
    except Exception as e:
        # Log errors with keyword arguments
        logger.error(f"Search failed", 
                    error_type=type(e).__name__,
                    error_message=str(e),
                    query=query)
        
        return {
            "status": "error",
            "error": str(e),
            "meta": {"query": query}
        }
```

## 9. Performance Considerations

When implementing agents and workflows, keep these performance considerations in mind:

### 9.1 Agent Initialization Cost

- Use lazy initialization to prevent unnecessary SDK calls
- Initialize agents only when needed, not at creation time
- Check if already initialized before reinitializing:

```python
async def initialize(self) -> None:
    """Initialize the agent with the OpenAI Agents SDK."""
    if self.is_initialized():
        return  # Prevent duplicate initialization
        
    # Initialization logic...
```

### 9.2 Context Size Management

- Be selective about data passing to avoid token limits
- Trim large outputs before storing in context:

```python
# Avoid storing extremely large outputs
if len(result) > 10000:  # Arbitrary limit
    trimmed_result = result[:9500] + "...[content trimmed]..."
    context.store_output(self.agent_id, trimmed_result)
    context.set_metadata(self.agent_id, {"trimmed": True, "original_size": len(result)})
else:
    context.store_output(self.agent_id, result)
```

### 9.3 Error Recovery

- Implement graceful degradation with actionable error information
- Return partial results when possible:

```python
try:
    # Operation
except Exception as e:
    logger.warning(f"Operation partially failed: {str(e)}")
    return {
        "status": "partial",
        "result": partial_result,
        "error": str(e)
    }
```

### 9.4 Memory Efficiency

- Use stateless design where possible to minimize resource usage
- Clean up large objects when no longer needed:

```python
def cleanup(self):
    """Release memory-intensive resources."""
    if hasattr(self, '_large_cache'):
        del self._large_cache
    # Other cleanup...
```