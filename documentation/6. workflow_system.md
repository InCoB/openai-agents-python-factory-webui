# workflow-system.md

# Workflow System

The Workflow System orchestrates agent execution, providing different execution strategies and patterns for coordinating multiple agents to complete complex tasks.

## Engine Core

```python
from aigen.workflows.engine import WorkflowEngine
from aigen.core.context import Context

# Create workflow engine
engine = WorkflowEngine(max_retries=3, retry_delay=5)

# Execute a workflow with a context
context = Context()
result = await engine.execute(workflow, context, "Input prompt")

# Get workflow status
status = engine.get_workflow_status(result["workflow_id"])
```

## Deterministic Workflow

Sequential execution of agents:

```python
from aigen.workflows import DeterministicWorkflow
from aigen.agents import create_agent

# Create agents
research_agent = create_agent("research")
writer_agent = create_agent("writer")
editor_agent = create_agent("editor")

# Create workflow with fixed sequence
workflow = DeterministicWorkflow(
    agents=[research_agent, writer_agent, editor_agent],
    name="content_generation"
)

# Execute
result = await engine.execute(workflow, context, "Generate content about AI")
final_content = result["result"]
```

## Handoff Workflow

Dynamic handoffs between agents:

```python
from aigen.workflows import HandoffWorkflow
from aigen.agents import create_agent

# Create agents
triage_agent = create_agent("orchestrator")
research_agent = create_agent("research")
writer_agent = create_agent("writer")

# Configure handoffs
triage_agent.add_handoff(research_agent.agent_id)
research_agent.add_handoff(writer_agent.agent_id)

# Create handoff workflow
workflow = HandoffWorkflow(
    agents=[triage_agent, research_agent, writer_agent],
    name="dynamic_content"
)

# Execute - agents will determine the flow dynamically
result = await engine.execute(workflow, context, "Research and write about quantum computing")
```

## Workflow Factory

```python
from aigen.workflows.factory import create_workflow, register_workflow_factory

# Register custom workflow
register_workflow_factory(
    "my_workflow",
    lambda **kwargs: DeterministicWorkflow(agents=[...], **kwargs),
    {"description": "Custom workflow implementation"}
)

# Create a workflow by name
workflow = create_workflow("content_generation")

# Create from agent list
workflow = create_workflow(["research", "writer", "editor"])

# Create from config file
workflow = create_workflow("workflows/my_workflow.yaml")
```

## Implementing Workflow Tracing

Proper workflow tracing enables you to monitor and debug the execution flow of agents within your workflows by integrating with OpenAI's tracing system.

### Deterministic Workflow Tracing

In `aigen/workflows/deterministic.py`, wrap the `execute_deterministic` method in a trace:

```python
from agents import trace, gen_trace_id

async def execute_deterministic(self, context: Context, input_text: Optional[str] = None) -> str:
    """Execute agents in a fixed sequence with explicit data passing."""
    start_time = time.time()
    
    if not self.agents:
        raise WorkflowError("No agents in workflow", workflow_id=self.name)
    
    logger.info(f"Starting deterministic workflow with {len(self.agents)} agents")
    
    # Generate a unique trace ID for this workflow execution using the SDK
    trace_id = gen_trace_id()
    
    # Wrap the entire agent sequence in a single trace for proper context flow
    with trace(f"Workflow: {self.name}", trace_id=trace_id):
        # Initialize current_input with the provided input_text
        current_input = input_text
        
        # Process agents in sequence with step-by-step data passing
        for i, agent in enumerate(self.agents):
            agent_id = agent.agent_id
            logger.info(f"Running agent {i+1}/{len(self.agents)}: {agent_id}")
            
            # Execute the agent with retry logic
            response = await self.engine.execute_agent(agent, context, current_input)
            
            if not response.success:
                # Handle agent failure
                if i > 0:
                    logger.warning(f"Agent {agent_id} failed but we have partial results")
                    return self._get_best_content(context)
                else:
                    error = f"Initial agent {agent_id} failed: {response.content}"
                    logger.error(error)
                    raise WorkflowError(error, workflow_id=self.name)
            
            # Update current_input for the next agent
            if i < len(self.agents) - 1:
                next_agent_id = self.agents[i+1].agent_id
                current_input = f"""
                Previous agent '{agent_id}' output:
                {response.content}
                
                Original request: {input_text}
                
                Now you ({next_agent_id}) should continue processing based on this.
                """
        
        # Get the final output
        final_agent_id = self.agents[-1].agent_id
        final_output = context.get_output(final_agent_id)
        
        if not final_output:
            logger.warning("No output from final agent, attempting to get best available content")
            return self._get_best_content(context)
        
        elapsed_time = time.time() - start_time
        logger.info(f"Deterministic workflow completed in {elapsed_time:.2f}s")
        
        return final_output
```

### Handoff Workflow Tracing

Similarly update the `execute_handoff` method in `aigen/workflows/handoff.py`:

```python
from agents import trace, gen_trace_id

async def execute_handoff(self, context: Context, input_text: Optional[str] = None) -> str:
    """Execute the workflow using agent handoffs."""
    start_time = time.time()
    
    if not self.agents:
        raise WorkflowError("No agents in workflow", workflow_id=self.name)
    
    logger.info(f"Starting handoff workflow with {len(self.agents)} agents")
    
    # Generate a unique trace ID using the SDK
    trace_id = gen_trace_id()
    
    # Wrap the entire execution in a trace
    with trace(f"Handoff: {self.name}", trace_id=trace_id):
        # Initialize hooks
        from ..core.hooks import ContentWorkflowHooks
        hooks = ContentWorkflowHooks()
        
        # Start with the first agent
        entry_agent = self.agents[0]
        
        try:
            # Execute the workflow through OpenAI Runner
            result = await Runner.run(
                entry_agent.openai_agent,
                input=input_text,
                context=context,
                max_turns=80,
                hooks=hooks
            )
```

## Specialized Workflow Patterns

Beyond the standard deterministic and handoff workflows, you can create specialized workflow patterns for specific domains:

### Branching Workflows

Create workflows that can take different paths based on context or input:

```python
async def execute_branching_workflow(context: Context, input_text: str) -> str:
    """Execute a workflow with conditional branching based on content type."""
    
    # First, analyze the input to determine the content type
    analysis_agent = create_agent("strategy", 
                                 instructions="Analyze the input and classify it as technical, creative, or general.")
    
    analysis_response = await analysis_agent.execute(context, input_text)
    content_type = _extract_content_type(analysis_response.content)
    
    # Create different workflow paths based on content type
    if content_type == "technical":
        workflow = create_workflow([
            "research", 
            "technical_writer",  # Specialized technical writer
            "technical_editor"   # Specialized technical editor
        ])
    elif content_type == "creative":
        workflow = create_workflow([
            "creative_research",  # More open-ended research
            "writer",
            "creative_editor"     # Focus on style and engagement
        ])
    else:  # General content
        workflow = create_workflow("content_generation")  # Standard workflow
    
    # Execute the selected workflow
    engine = WorkflowEngine()
    result = await engine.execute(workflow, context, input_text)
    
    return result["result"]

def _extract_content_type(analysis_text: str) -> str:
    """Extract content type from analysis text."""
    analysis_text = analysis_text.lower()
    
    if "technical" in analysis_text:
        return "technical"
    elif "creative" in analysis_text:
        return "creative"
    else:
        return "general"
```

### Parallel Workflows with Aggregation

Run multiple workflows in parallel and combine their results:

```python
async def execute_parallel_workflows(context: Context, input_text: str) -> str:
    """Execute multiple workflows in parallel and aggregate results."""
    
    # Create different workflow configurations
    workflows = {
        "technical": create_domain_workflow("technical"),
        "creative": create_domain_workflow("creative"),
        "general": create_workflow("content_generation")
    }
    
    # Create isolated contexts for each workflow
    contexts = {name: Context() for name in workflows.keys()}
    
    # Execute workflows in parallel
    engine = WorkflowEngine()
    tasks = {
        name: engine.execute(workflow, contexts[name], input_text)
        for name, workflow in workflows.items()
    }
    
    # Wait for all workflows to complete
    import asyncio
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)
    workflow_results = dict(zip(tasks.keys(), results))
    
    # Create an aggregation agent to combine results
    aggregator = create_agent("editor", 
                            instructions="Combine the different content versions into a cohesive final piece.")
    
    # Prepare combined input for the aggregator
    combined_input = f"Original request: {input_text}\n\n"
    for name, result in workflow_results.items():
        if isinstance(result, Exception):
            combined_input += f"{name.upper()} VERSION: Error - {str(result)}\n\n"
        else:
            combined_input += f"{name.upper()} VERSION:\n{result.get('result', 'No result')}\n\n"
    
    # Get the aggregated result
    aggregated_response = await aggregator.execute(context, combined_input)
    
    return aggregated_response.content
```

### Self-Improving Workflows

Create workflows that can evaluate and improve their own output:

```python
async def execute_self_improving_workflow(context: Context, input_text: str, max_iterations: int = 3) -> str:
    """Execute a workflow that can critique and improve its own output."""
    
    # Create the base content generation workflow
    workflow = create_workflow("content_generation")
    
    # Create a critique agent
    critique_agent = create_agent("editor", 
                                instructions="Critically evaluate the content and suggest specific improvements.")
    
    # Create a revision agent
    revision_agent = create_agent("writer", 
                                instructions="Revise the content based on the critique.")
    
    # Initial content generation
    engine = WorkflowEngine()
    result = await engine.execute(workflow, context, input_text)
    current_content = result["result"]
    
    # Iterative improvement loop
    for i in range(max_iterations):
        # Get critique
        critique_input = f"Original request: {input_text}\n\nCurrent content:\n{current_content}"
        critique_response = await critique_agent.execute(context, critique_input)
        critique = critique_response.content
        
        # Check if critique suggests major improvements
        if "excellent" in critique.lower() and "no improvements needed" in critique.lower():
            logger.info(f"Content reached excellent quality at iteration {i+1}")
            break
        
        # Revise based on critique
        revision_input = f"Original request: {input_text}\n\nCurrent content:\n{current_content}\n\nCritique:\n{critique}"
        revision_response = await revision_agent.execute(context, revision_input)
        current_content = revision_response.content
        
        logger.info(f"Completed revision iteration {i+1}/{max_iterations}")
    
    return current_content
```

## Workflow Factory Registration Issues

The system can encounter factory registration issues where workflow factories are not callable. To prevent or fix these problems:

### Direct Workflow Creation in create_workflow()

Add direct creation paths for commonly used workflows:

```python
def create_workflow(workflow_spec: str, **kwargs):
    """Create a workflow with direct fallbacks for reliability."""
    
    # Direct fallbacks for common workflows
    if workflow_spec == "research_only":
        logger.info("Creating research_only workflow directly")
        from .deterministic import DeterministicWorkflow
        from ..agents.factory import create_agent
        return DeterministicWorkflow(
            agents=[create_agent("research")],
            name="research_only"
        )
    elif workflow_spec == "content_generation":
        logger.info("Creating content_generation workflow directly")
        from .deterministic import DeterministicWorkflow
        from ..agents.factory import create_agent
        return DeterministicWorkflow(
            agents=[
                create_agent("research"),
                create_agent("strategy"),
                create_agent("writer"),
                create_agent("editor")
            ],
            name="content_generation"
        )
    
    # Continue with standard workflow creation logic...
```

### Always Check Registry First in workflow_by_type

Ensure `create_workflow_by_type` always checks the registry before trying other methods:

```python
def create_workflow_by_type(workflow_type: str, **kwargs):
    """Create a workflow by type with proper registry checking."""
    
    # Always check registry first
    if workflow_type in workflow_registry.list():
        factory = workflow_registry.get(workflow_type)
        if callable(factory):
            try:
                return factory(**kwargs)
            except Exception as e:
                logger.warning(f"Factory call failed: {str(e)}")
                # Fall back to other methods
    
    # Standard types fallback
    if workflow_type == 'deterministic':
        from .deterministic import DeterministicWorkflow
        return DeterministicWorkflow(**kwargs)
    elif workflow_type == 'handoff':
        from .handoff import HandoffWorkflow
        return HandoffWorkflow(**kwargs)
    
    # Dynamic import as last resort
    try:
        module = importlib.import_module(f"aigen.workflows.{workflow_type.lower()}")
        class_name = "".join(word.capitalize() for word in workflow_type.split("_")) + "Workflow"
        workflow_class = getattr(module, class_name)
        return workflow_class(**kwargs)
    except (ImportError, AttributeError):
        raise ValueError(f"Unsupported workflow type: {workflow_type}")
```