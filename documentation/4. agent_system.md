# workflow-system.md

# Workflow System

The Workflow System orchestrates agent execution, providing different execution strategies and patterns for coordinating multiple agents to complete complex tasks.

## Engine Core

```python
from aigen.workflows.engine import WorkflowEngine
from aigen.core.context import Context

# Create workflow engine
engine = WorkflowEngine(max_retries=3, retry_delay=5)

# Execute a workflow with a context
context = Context()
result = await engine.execute(workflow, context, "Input prompt")

# Get workflow status
status = engine.get_workflow_status(result["workflow_id"])
```

## Deterministic Workflow

Sequential execution of agents:

```python
from aigen.workflows import DeterministicWorkflow
from aigen.agents import create_agent

# Create agents
research_agent = create_agent("research")
writer_agent = create_agent("writer")
editor_agent = create_agent("editor")

# Create workflow with fixed sequence
workflow = DeterministicWorkflow(
    agents=[research_agent, writer_agent, editor_agent],
    name="content_generation"
)

# Execute
result = await engine.execute(workflow, context, "Generate content about AI")
final_content = result["result"]
```

## Handoff Workflow

Dynamic handoffs between agents:

```python
from aigen.workflows import HandoffWorkflow
from aigen.agents import create_agent

# Create agents
triage_agent = create_agent("orchestrator")
research_agent = create_agent("research")
writer_agent = create_agent("writer")

# Configure handoffs
triage_agent.add_handoff(research_agent.agent_id)
research_agent.add_handoff(writer_agent.agent_id)

# Create handoff workflow
workflow = HandoffWorkflow(
    agents=[triage_agent, research_agent, writer_agent],
    name="dynamic_content"
)

# Execute - agents will determine the flow dynamically
result = await engine.execute(workflow, context, "Research and write about quantum computing")
```

## Workflow Factory

```python
from aigen.workflows.factory import create_workflow, register_workflow_factory

# Register custom workflow
register_workflow_factory(
    "my_workflow",
    lambda **kwargs: DeterministicWorkflow(agents=[...], **kwargs),
    {"description": "Custom workflow implementation"}
)

# Create a workflow by name
workflow = create_workflow("content_generation")

# Create from agent list
workflow = create_workflow(["research", "writer", "editor"])

# Create from config file
workflow = create_workflow("workflows/my_workflow.yaml")
```

## Implementing Workflow Tracing

Proper workflow tracing enables you to monitor and debug the execution flow of agents within your workflows by integrating with OpenAI's tracing system.

### Deterministic Workflow Tracing

In `aigen/workflows/deterministic.py`, wrap the `execute_deterministic` method in a trace:

```python
from agents import trace, gen_trace_id

async def execute_deterministic(self, context: Context, input_text: Optional[str] = None) -> str:
    """Execute agents in a fixed sequence with explicit data passing."""
    start_time = time.time()
    
    if not self.agents:
        raise WorkflowError("No agents in workflow", workflow_id=self.name)
    
    logger.info(f"Starting deterministic workflow with {len(self.agents)} agents")
    
    # Generate a unique trace ID for this workflow execution using the SDK
    trace_id = gen_trace_id()
    
    # Wrap the entire agent sequence in a single trace for proper context flow
    with trace(f"Workflow: {self.name}", trace_id=trace_id):
        # Initialize current_input with the provided input_text
        current_input = input_text
        
        # Process agents in sequence with step-by-step data passing
        for i, agent in enumerate(self.agents):
            agent_id = agent.agent_id
            logger.info(f"Running agent {i+1}/{len(self.agents)}: {agent_id}")
            
            # Execute the agent with retry logic
            response = await self.engine.execute_agent(agent, context, current_input)
            
            if not response.success:
                # Handle agent failure
                if i > 0:
                    logger.warning(f"Agent {agent_id} failed but we have partial results")
                    return self._get_best_content(context)
                else:
                    error = f"Initial agent {agent_id} failed: {response.content}"
                    logger.error(error)
                    raise WorkflowError(error, workflow_id=self.name)
            
            # Update current_input for the next agent
            if i < len(self.agents) - 1:
                next_agent_id = self.agents[i+1].agent_id
                current_input = f"""
                Previous agent '{agent_id}' output:
                {response.content}
                
                Original request: {input_text}
                
                Now you ({next_agent_id}) should continue processing based on this.
                """
        
        # Get the final output
        final_agent_id = self.agents[-1].agent_id
        final_output = context.get_output(final_agent_id)
        
        if not final_output:
            logger.warning("No output from final agent, attempting to get best available content")
            return self._get_best_content(context)
        
        elapsed_time = time.time() - start_time
        logger.info(f"Deterministic workflow completed in {elapsed_time:.2f}s")
        
        return final_output
```

### Handoff Workflow Tracing

Similarly update the `execute_handoff` method in `aigen/workflows/handoff.py`:

```python
from agents import trace, gen_trace_id

async def execute_handoff(self, context: Context, input_text: Optional[str] = None) -> str:
    """Execute the workflow using agent handoffs."""
    start_time = time.time()
    
    if not self.agents:
        raise WorkflowError("No agents in workflow", workflow_id=self.name)
    
    logger.info(f"Starting handoff workflow with {len(self.agents)} agents")
    
    # Generate a unique trace ID using the SDK
    trace_id = gen_trace_id()
    
    # Wrap the entire execution in a trace
    with trace(f"Handoff: {self.name}", trace_id=trace_id):
        # Initialize hooks
        from ..core.hooks import ContentWorkflowHooks
        hooks = ContentWorkflowHooks()
        
        # Start with the first agent
        entry_agent = self.agents[0]
        
        try:
            # Execute the workflow through OpenAI Runner
            result = await Runner.run(
                entry_agent.openai_agent,
                input=input_text,
                context=context,
                max_turns=80,
                hooks=hooks
            )
```

## Specialized Workflow Patterns

Beyond the standard deterministic and handoff workflows, you can create specialized workflow patterns for specific domains:

### Branching Workflows

Create workflows that can take different paths based on context or input:

```python
async def execute_branching_workflow(context: Context, input_text: str) -> str:
    """Execute a workflow with conditional branching based on content type."""
    
    # First, analyze the input to determine the content type
    analysis_agent = create_agent("strategy", 
                                 instructions="Analyze the input and classify it as technical, creative, or general.")
    
    analysis_response = await analysis_agent.execute(context, input_text)
    content_type = _extract_content_type(analysis_response.content)
    
    # Create different workflow paths based on content type
    if content_type == "technical":
        workflow = create_workflow([
            "research", 
            "technical_writer",  # Specialized technical writer
            "technical_editor"   # Specialized technical editor
        ])
    elif content_type == "creative":
        workflow = create_workflow([
            "creative_research",  # More open-ended research
            "writer",
            "creative_editor"     # Focus on style and engagement
        ])
    else:  # General content
        workflow = create_workflow("content_generation")  # Standard workflow
    
    # Execute the selected workflow
    engine = WorkflowEngine()
    result = await engine.execute(workflow, context, input_text)
    
    return result["result"]

def _extract_content_type(analysis_text: str) -> str:
    """Extract content type from analysis text."""
    analysis_text = analysis_text.lower()
    
    if "technical" in analysis_text:
        return "technical"
    elif "creative" in analysis_text:
        return "creative"
    else:
        return "general"
```

### Parallel Workflows with Aggregation

Run multiple workflows in parallel and combine their results:

```python
async def execute_parallel_workflows(context: Context, input_text: str) -> str:
    """Execute multiple workflows in parallel and aggregate results."""
    
    # Create different workflow configurations
    workflows = {
        "technical": create_domain_workflow("technical"),
        "creative": create_domain_workflow("creative"),
        "general": create_workflow("content_generation")
    }
    
    # Create isolated contexts for each workflow
    contexts = {name: Context() for name in workflows.keys()}
    
    # Execute workflows in parallel
    engine = WorkflowEngine()
    tasks = {
        name: engine.execute(workflow, contexts[name], input_text)
        for name, workflow in workflows.items()
    }
    
    # Wait for all workflows to complete
    import asyncio
    results = await asyncio.gather(*tasks.values(), return_exceptions=True)
    workflow_results = dict(zip(tasks.keys(), results))
    
    # Create an aggregation agent to combine results
    aggregator = create_agent("editor", 
                            instructions="Combine the different content versions into a cohesive final piece.")
    
    # Prepare combined input for the aggregator
    combined_input = f"Original request: {input_text}\n\n"
    for name, result in workflow_results.items():
        if isinstance(result, Exception):
            combined_input += f"{name.upper()} VERSION: Error - {str(result)}\n\n"
        else:
            combined_input += f"{name.upper()} VERSION:\n{result.get('result', 'No result')}\n\n"
    
    # Get the aggregated re